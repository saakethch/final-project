{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\College\\7374\\FinalProject\\env\\lib\\site-packages\\snowflake\\connector\\options.py:107: UserWarning: You have an incompatible version of 'pyarrow' installed (11.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == \"pandas\"'\n",
      "  warn_incompatible_dep(\n",
      "Failed to import ArrowResult. No Apache Arrow result set format can be used. ImportError: DLL load failed while importing arrow_iterator: The specified procedure could not be found.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<snowflake.snowpark.session.Session at 0x1b71cfdd880>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snowflake.snowpark.session import Session\n",
    "import json\n",
    "connection_parameters = json.load(open('connection.json'))\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PutResult(source='download.png', target='download.png', source_size=4111, target_size=4112, source_compression='NONE', target_compression='NONE', status='UPLOADED', message='')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# session.sql('create or replace stage dash_udfs').collect()\n",
    "session.file.put(\"../temp/download.png\",'@dash_models',overwrite=True,auto_compress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.DataFrame({\"FILE_NAME\": [\"image1\"], \"OUTPUT\": [\"cat\"]})\n",
    "# s = session.sql(\"session.sql('create database if not exists IMAGES')\")\n",
    "# s\n",
    "# session.write_pandas(df, \"IMAGES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PutResult(source='image_1.jpeg', target='image_1.jpeg', source_size=26237, target_size=26240, source_compression='NONE', target_compression='NONE', status='UPLOADED', message='')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.file.put('../temp/image_1.jpeg','@dash_models',overwrite=True,auto_compress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Model Directory\n",
    "directory = '../model/'\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    if os.path.isfile(f):\n",
    "        # Import trained model\n",
    "        # session.file.put(f,'@dash_models',overwrite=True,auto_compress=False)\n",
    "        session.add_import('@dash_models/'+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PutResult(source='image.jpg', target='image.jpg', source_size=85949, target_size=85952, source_compression='NONE', target_compression='NONE', status='UPLOADED', message='')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.file.put(\"../backend/images/image.jpg\",'@dash_models',overwrite=True,auto_compress=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.functions import udf, sum, col,array_construct,month,year,call_udf,lit\n",
    "import os\n",
    "from snowflake.snowpark.types import  StringType, IntegerType\n",
    "\n",
    "# session.add_import('@dash_models/m/tokenizer.json')\n",
    "# session.add_import('@dash_models/pytorch_model.bin')\n",
    "# session.add_import('@dash_files/mobilenetv3.py')\n",
    "session.add_import('@dash_models/image.jpg')\n",
    "@udf(name='image_caption_generator',session=session,replace=True,is_permanent=True,stage_location='@dash_models')\n",
    "def image_caption_generator() -> str:\n",
    "  from transformers import VisionEncoderDecoderModel, ViTFeatureExtractor, AutoTokenizer\n",
    "  import torch\n",
    "  import sys\n",
    "  from PIL import Image\n",
    "  from io import BytesIO\n",
    "  import requests\n",
    "  import glob \n",
    "  IMPORT_DIRECTORY_NAME = \"snowflake_import_directory\"\n",
    "  import_dir = sys._xoptions[IMPORT_DIRECTORY_NAME]\n",
    "  # return os.listdir(import_dir)\n",
    "  \n",
    "  model_path = import_dir\n",
    "\n",
    "  model = VisionEncoderDecoderModel.from_pretrained(model_path)\n",
    "  feature_extractor = ViTFeatureExtractor.from_pretrained(model_path)\n",
    "  tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "  image_file_name = \"/image.jpg\"\n",
    "  device = torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\")\n",
    "  model.to(device)\n",
    "  max_length = 16\n",
    "  num_beams = 4\n",
    "  gen_kwargs = {\"max_length\": max_length, \"num_beams\": num_beams}\n",
    "  images = []\n",
    "  i_image = Image.open(model_path+image_file_name)\n",
    "  if i_image.mode != \"RGB\":\n",
    "    i_image = i_image.convert(mode=\"RGB\")\n",
    "\n",
    "  images.append(i_image)\n",
    "\n",
    "  pixel_values = feature_extractor(images=images, return_tensors=\"pt\").pixel_values\n",
    "  pixel_values = pixel_values.to(device)\n",
    "\n",
    "  output_ids = model.generate(pixel_values, **gen_kwargs)\n",
    "\n",
    "  preds = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "  preds = [pred.strip() for pred in preds]\n",
    "  # os.remove(model_path+\"downloa\")\n",
    "  return preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_raw_caption(image_link : str) -> str:\n",
    "    # Snowpark imports \n",
    "    from snowflake.snowpark.session import Session\n",
    "    import json\n",
    "    connection_parameters = json.load(open('connection.json'))\n",
    "    session = Session.builder.configs(connection_parameters).create()\n",
    "    # ... continued in backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_links_in_str = [\"https://as2.ftcdn.net/v2/jpg/03/03/62/45/1000_F_303624505_u0bFT1Rnoj8CMUSs8wMCwoKlnWlh5Jiq.jpg\"]\n",
    "predicted_label = session.sql('''SELECT image_caption_generator()''').collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a wooden table topped with a wooden table cloth'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_label[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of package transformers in the local environment is 4.28.1, which does not fit the criteria for the requirement transformers. Your UDF might not work when the package version is different between the server and your local environment\n",
      "The version of package pillow in the local environment is 9.5.0, which does not fit the criteria for the requirement pillow. Your UDF might not work when the package version is different between the server and your local environment\n"
     ]
    }
   ],
   "source": [
    "session.add_packages([\"transformers\",\"Pillow\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.clear_imports()\n",
    "session.clear_packages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
